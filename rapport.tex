\documentclass{article}
\usepackage{fancyvrb}
\usepackage{a4wide}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{empheq}
\usepackage{mathtools, bm}
\usepackage{amssymb, bm}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{csvsimple}
\usepackage{float}

\title{\textbf{\Huge  Université Paris Saclay}\\ Rapport IAS}
\author{Guillaume Abadie, Jérôme Coquisart, Mathis Dupont, Martin Vitani}
\date{Année 2021}


\begin{document}
    \maketitle
    \vspace{100px}
    \tableofcontents
    \newpage

    \section{Introduction au problème}
    La ville de Chicago a un ratio de crimes, surtout sur les crimes violents,
    au dessus de la moyenne nationale des États-Unis.
    Les crimes dans la ville ont été collectés dès le début du 20ème siècle pour
    essayer de comprendre pourquoi la ville était sujette à autant de violence.
    Le dataset correspond aux crimes commis entre 2001 et 2020, et contient environ 
    7 millions d'entrées.
    Tous les jours, la police de Chicago alimente la base de donnée avec les
    nouveaux crimes commis dans la ville. 
    Seuls les meurtres ne sont pas comptabilisé dans la base de donnée.

    \section{Aperçu du dataset}
    \begin{figure}[H]
	    \centering
	    \begin{subfigure}{.45\textwidth}
		    \includegraphics[scale=.2]{Images/typeArrestation.png}
		    \caption{Types de crimes avec le plus d'arrestation}
	    \end{subfigure}
	    \begin{subfigure}{.45\textwidth}
		    \includegraphics[scale=.2]{Images/pprimarytype.png}
		    \caption{Pourcentage de crimes en fonction de leurs type}
	    \end{subfigure}
	    \includegraphics[scale=.2]{Images/carte_chicago.png}
	    \caption{Carte représentant l'ensemble des crimes commis à Chicago}
    \end{figure}
    Sur cette carte, chaque point représente un crime.

    \section{Définition du problème}
    Notre problème sera le suivant. Il s'agira de déterminer si il y aura
    oui ou non une arrestation à la suite d'un crime. 
    Pour être plus précis, étant donné le lieu, la description et la date du crime, 
    il faudra dire si cela va mener à l'arrestation d'un suspect.
    C'est une tâche de classification
    binaire, en apprentissage supervisé.

    \section{Préprocessing}
    Comme le dataset contenait peu de features, 
    nous avons effectué plusieurs modifications sur le dataset 
    avant d'entrainer notre modèle.
    De plus, certaines features étaient uniques pour chacun de nos crimes.

    Nous avons tout d'abord supprimer les données qui contenaient des features vides,
    et nous avons
    équilibré le dataset.
    Cela a été fait avec des commandes shell pour la rapidité et la simplicité. 
    On rappelle que notre dataset contient 7 millions d'entrées à la base.
    Voici les commandes effectuées.

    \begin{Verbatim}
    ## Nettoyer les données
    grep -v -E '(,0,0,2)|(,,)' Crimes2001.csv  > CrimesClean.csv
    
    ## Equilibrer les données
    # Ici on sépares à l'aide d'expressions régulières les arrested et les non arrested
    grep -E '^(([^,]*,)|("[^"]*",)){8}false' Crimes100K.csv > CrimesCleanNonArrested.csv
    grep -E '^(([^,]*,)|("[^"]*",)){8}true' Crimes100K.csv > CrimesCleanArrested.csv
    
    # Ici on recombine en n'oubliant pas le header contenant le nom des features
    head -n 1 CrimesClean.csv > CrimesEq.csv
    n=$(wc -l CrimesCleanArrested.csv | grep -E -o '[0-9]+ ')
    cp CrimesCleanArrested.csv tmp.csv
    shuf -n $n CrimesCleanNonArrested.csv >> tmp.csv
    shuf tmp.csv >> CrimesEq.csv
    \end{Verbatim}

    Ensuite, en python, nous avons supprimé les features uniques et
    celles qui se répétaient
    \begin{itemize}
	    \item ID
	    \item Case Number
	    \item Block
	    \item Updated On
	    \item Longitude
	    \item Latitude
	    \item Location
    \end{itemize}
    À partir de la feature \textit{date}, nous avons extrait les features suivantes
    \begin{itemize}
	    \item Part of the day
	    \item Weekday
	    \item Weekend
	    \item Month
	    \item Hour
    \end{itemize}
    Enfin, à partir des coordonnées géographiques, nous avons appliqué un algorithme
    de k-moyennes pour séparer les zones de Chicago et en déduire une nouvelle
    feature \textit{Cluster}. 
    Voici ce que l'on obtiens lorsque l'on affiche la localisation des crimes en
    fonction de leurs clusters.
    \begin{figure}[H]
    \centering
	    \includegraphics[scale=.2]{Images/carte_densité.png}
	    \caption{Clusters des crimes de Chicago}
    \end{figure}
    Sur cette dernière carte, les clusters plus rouges concentrent le plus de crimes.

    \section{Choix d'algorithme}
    Comme notre dataset est assez conséquent, nous avons utilisé les algorithmes 
    de la bibliothèque \textit{scikit-learn}.
    Pour classifier nos crimes, nous utilisons le DecisionTree et le modèle Gaussien Naïf.
    Différentes fonctions dans le fichier main.py nous ont permis de déterminer
    les meilleurs hyper-paramètres à choisir pour le DecisionTree.
    \begin{figure}[H]
            \centering
	    \includegraphics[scale=.4]{bestParamDecisionTree.png}
	    \caption{Cross-validation pour le DecisionTree}
    \end{figure}

    \section{Comparaison des modèles}
    \begin{figure}[H]
            \centering
	    \includegraphics[scale=.35]{Images/feature_importance.png}
	    \caption{Importance des features pour le DecisionTree}
    \end{figure}

    L'arbre de décision est un algorithme de classification qui nous aide 
    à prendre des décision :
    selon le type de crime, selon le lieu, le moment etc., y a-t-il eu arrestation ou pas?
    Pour chaque features, il essaye de répondre à des questions sur celles-ci afin
    de les séparer en différentes catégorie : 
    Le crime a-t-il eu lieu sur la place publique ou dans un appartement?
    (on peut voir sur la figure 4 que \textit{location description} est une feature
    importante à la décision, car la question posée sur cette feature est pertinente).
    L'arbre de décision que nous avons obtenue est vraiment grand, car beaucoup de
    features, "mais nous avons crée un DecisionTree avec une partie restreinte de
    nos features afin de pouvoir le regarder : ??"

    Le modèle bayésien naïf est un modèle basé sur l'EMV
    (Estimateur du Maximum de Vraisemblance).
    Le but est simple, maximiser la vraisemblance. 
    Cependant une hypothèse importante de ce modèle est l'indépendance de chaque données,
    ce qui n'est pas du tout notre cas dans ce projet.
    Ainsi, on peut prévoir une score moyen pour ce modèle avec nos données.

    Comme nous avons beaucoup de données (1M pour les calculs des scores),
    le bayésien naïf va avoir du mal, alors que cela ne pas changer grand
    chose pour le DecisionTree.

    \section{Présentation des résultats}

    \begin{figure}[H]
            \centering
	    \includegraphics[scale=.35]{Images/Matrice de confusion.png}
	    \caption{Matrice de confusion du DecisionTree}
    \end{figure}

    Voici la matrice de confusion générée à partir de l'arbre décision, entrainé sur
    nos 1 millions de données. On peut voir que notre modèle arrive mieux à valider
    le fait qu'il y ai arrestation que le fait qu'il n'y ai pas d'arrestation.

    Les scores obtenues pour nos deux modèles sont :
    \begin{Verbatim}
    Score GaussNB :  0.703753
    Score DecisionTree :  0.82345
    \end{Verbatim}

    La comparaison des modèles nous a donné raison, l'arbre de décision nous donne
    un meilleur score que le bayésien naïf.

    \section{Conclusion}

\end{document}
