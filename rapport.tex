\documentclass{article}
\usepackage{fancyvrb}
\usepackage{a4wide}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{empheq}
\usepackage{mathtools, bm}
\usepackage{amssymb, bm}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{csvsimple}
\usepackage{float}
\usepackage{wrapfig}

\title{\textbf{\Huge  Université Paris Saclay}\\ Rapport IAS}
\author{Guillaume Abadie, Jérôme Coquisart, Mathis Dupont, Martin Vitani}
\date{Année 2021}


\begin{document}
    \maketitle
    %\vspace{100px}
    \tableofcontents

    \section{Introduction au problème}
    La ville de Chicago a un ratio de crimes, surtout sur les crimes violents,
    au dessus de la moyenne nationale des États-Unis.
    Les crimes dans la ville ont été collectés dès le début du 20ème siècle pour
    essayer de comprendre pourquoi la ville était sujette à autant de violence.
    Le dataset correspond aux crimes commis entre 2001 et 2020, et contient environ 
    7 millions d'entrées.
    Tous les jours, la police de Chicago alimente la base de donnée avec les
    nouveaux crimes commis dans la ville. 
    Parmi les données collectées, on retrouve: 
    cambriolages, agressions, homicides, vols, braquages, intimidations, kidnapping, 
    possession d'arme\dots.
    Seuls les meurtres ne sont pas comptabilisés dans la base de donnée.

    \section{Aperçu du dataset}
    \begin{figure}[H]
	    \centering
	    \begin{subfigure}{.45\textwidth}
		    \includegraphics[scale=.2]{images/pprimarytype.png}
		    \caption{Pourcentage de crimes en fonction de leurs type}
	    \end{subfigure}
	    \begin{subfigure}{.45\textwidth}
		    \includegraphics[scale=.2]{images/typeArrestation.png}
		    \caption{Types de crimes avec le plus d'arrestation}
	    \end{subfigure}
	    \caption{Aperçu }
    \end{figure}
    La figure (a) nous montre que les crimes les plus représentés sont les 
    agressions (\textit{battery}), le trafic de de drogue (\textit{narcotics}) 
    et les vols (\textit{threft}).

    \begin{wrapfigure}{r}{0.5\textwidth}
	    \centering
	    \includegraphics[width=0.5\textwidth]{images/carte_chicago.png}
	    \caption{Carte représentant l'ensemble des crimes commis à Chicago}
    \end{wrapfigure}

    D'après la figure (b), on voit que certains crimes sont quasiment toujours suivis 
    d'une arrestation, c'est le cas des paris illégaux, du port d'armes caché, 
    des crime liés à l'alcool et l'obscénité.
    Cette même figure nous apprend qu'il y a moins de 20\% d'arrestation pour les 
    cambriolages, le trafic d'humain, les braquages et les vols de véhicules motorisés.
    Enfin, on voit sur la Figure 2 la carte de Chicago se dessiner, où chaque
    point représente un crime.


    \section{Définition du problème}
    Notre problème sera le suivant. Il s'agira de déterminer si il y aura
    oui ou non une arrestation à la suite d'un crime. 
    Pour être plus précis, étant donné le lieu, la description et la date du crime, 
    il faudra dire si cela va mener à l'arrestation d'un suspect.
    C'est une tâche de classification
    binaire, en apprentissage supervisé.

    \section{Préprocessing}
    Comme le dataset contenait peu de features, 
    nous avons effectué plusieurs modifications sur le dataset 
    avant d'entrainer notre modèle.
    De plus, certaines features étaient uniques pour chacun de nos crimes.

    Nous avons tout d'abord supprimé les données qui contenaient des features vides,
    et nous avons
    équilibré le dataset.
    Cela a été fait avec des commandes shell pour la rapidité et la simplicité. 
    On rappelle que notre dataset contient 7 millions d'entrées à la base.
    Voici les commandes effectuées.

    \begin{Verbatim}
    ## Nettoyer les données
    grep -v -E '(,0,0,2)|(,,)' Crimes2001.csv  > CrimesClean.csv
    
    ## Equilibrer les données
    # Ici on sépares à l'aide d'expressions régulières les arrested et les non arrested
    grep -E '^(([^,]*,)|("[^"]*",)){8}false' Crimes100K.csv > CrimesCleanNonArrested.csv
    grep -E '^(([^,]*,)|("[^"]*",)){8}true' Crimes100K.csv > CrimesCleanArrested.csv
    
    # Ici on recombine en n'oubliant pas le header contenant le nom des features
    head -n 1 CrimesClean.csv > CrimesEq.csv
    n=$(wc -l CrimesCleanArrested.csv | grep -E -o '[0-9]+ ')
    cp CrimesCleanArrested.csv tmp.csv
    shuf -n $n CrimesCleanNonArrested.csv >> tmp.csv
    shuf tmp.csv >> CrimesEq.csv
    \end{Verbatim}

    \begin{wrapfigure}{r}{0.5\textwidth}
	    \centering
	    \includegraphics[width=0.5\textwidth]{images/carte_densité.png}
	    \caption{Clusters des crimes de Chicago}
    \end{wrapfigure}
    Ensuite, en python, nous avons supprimé les features uniques et
    celles qui se répétaient
    \begin{itemize}
	    \item ID
	    \item Case Number
	    \item Block
	    \item Updated On
	    \item Longitude
	    \item Latitude
	    \item Location
    \end{itemize}
    À partir de la feature \textit{date}, nous avons extrait les features suivantes
    \begin{itemize}
	    \item Part of the day
	    \item Weekday
	    \item Weekend
	    \item Month
	    \item Hour
    \end{itemize}
    Enfin, à partir des coordonnées géographiques, nous avons appliqué un algorithme
    de k-moyennes pour séparer les zones de Chicago et en déduire une nouvelle
    feature \textit{Cluster}. 
    Voici ce que l'on obtiens lorsque l'on affiche la localisation des crimes en
    fonction de leurs clusters.
    Sur cette dernière carte, les clusters plus rouges concentrent le plus de crimes.

    \section{Choix d'algorithme}
    Comme notre dataset est assez conséquent, nous avons utilisé les algorithmes 
    de la bibliothèque \textit{scikit-learn}.
    Pour classifier nos crimes, nous utilisons le DecisionTree et le modèle Gaussien Naïf.
    Différentes fonctions dans le fichier main.py nous ont permis de déterminer
    les meilleurs hyper-paramètres à choisir pour le DecisionTree.
    \begin{figure}[H]
	    \centering
	    \begin{subfigure}{.45\textwidth}
		    \includegraphics[scale=.2]{images/bestParamDecisionTree.png}
		    \caption{Cross-validation pour le DecisionTree}
	    \end{subfigure}
	    \begin{subfigure}{.45\textwidth}
		    \includegraphics[scale=.3]{images/bestNumClusters.png}
		    \caption{Choix du meilleur nombre de clusters}
	    \end{subfigure}
    \end{figure}
    Les hyper-paramètres qui ont été testés sont le \textit{min\_sample\_split}, le \textit{min\_sample\_leaf},
    le \textit{max\_features}, le \textit{min\_impurity\_decrease}, le nombre de clusters et le 
    nombre de données.
    On obtient respectivement 130, 60, max et 0 pour les paramètres du DecisionTree. On a donc sélectionné 60 clusters
    géographiques et on travaille avec 1M de données.

    Nous avons également essayé d'utiliser un RandomForestClassifier. Le score était substantiellement
    identique au DecsionTree, mais avec un temps de calcul deux à trois fois supérieur.

    \section{Comparaison des modèles}

    L'arbre de décision est un algorithme de classification qui nous aide 
    à prendre des décision:
    selon le type de crime, selon le lieu, le moment etc., y a-t-il eu arrestation ou pas?
    Pour chaque features, il essaye de répondre à des questions sur celles-ci afin
    de les séparer en différentes catégorie:
    Le crime a-t-il eu lieu sur la place publique ou dans un appartement?
    (on peut voir sur la Figure 5 que \textit{location description} est une feature
    importante à la décision, car la question posée sur cette feature est pertinente).
    L'arbre de décision que nous avons obtenue est vraiment grand, car beaucoup de
    features, mais nous avons créé un DecisionTree avec une partie restreinte de
    nos features afin de pouvoir le regarder: %TODO

    \begin{figure}[H]
            \centering
	    \includegraphics[scale=.3]{images/feature_importance.png}
	    \caption{Importance des features pour le DecisionTree}
    \end{figure}


    Le modèle bayésien naïf est un modèle basé sur l'EMV
    (Estimateur du Maximum de Vraisemblance).
    Le but est simple, maximiser la vraisemblance. 
    Cependant une hypothèse importante de ce modèle est l'indépendance de chaque données,
    ce qui n'est pas du tout notre cas dans ce projet.
    Ainsi, on peut prévoir une score moyen pour ce modèle avec nos données.

    Comme nous avons beaucoup de données (1M pour les calculs des scores),
    le bayésien naïf va avoir du mal, alors que cela ne pas changer grand
    chose pour le DecisionTree.

    \section{Présentation des résultats}

    \begin{figure}[H]
	    \begin{subfigure}{.45\textwidth}
		    \includegraphics[scale=.314]{images/MatriceConfusionDecisionTree.png}
		    \centering
		    \caption{Matrice de confusion du DecisionTree}
	    \end{subfigure}
	    \begin{subfigure}{.45\textwidth}
		    \centering
		    \includegraphics[scale=.35]{images/MatriceConfusionGauss.png}
		    \caption{Matrice de confusion du Bayésien Naïf}
	    \end{subfigure}
    \end{figure}

    Voici les matrices de confusion générée pour le DecisionTree et le modèle Bayésien Naïf,
    entrainés sur nos 1 millions de données. On peut voir que ces deux modèles arrivent 
    mieux à valider le fait qu'il y ait arrestation que le fait qu'il n'y ait pas d'arrestation.

    Après optimisation des paramètres, les scores obtenus pour nos deux modèles sont:
    \begin{Verbatim}
    Score GaussNB :  0.703753
    Score DecisionTree :  0.82345
    \end{Verbatim}

    La comparaison des modèles nous a donné raison, l'arbre de décision nous donne
    un meilleur score que le bayésien naïf.

    \section{Conclusion}

\end{document}
