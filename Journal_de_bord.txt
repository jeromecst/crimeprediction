=== 28 MARS 2021 ===

1)
Création de la fonction split_date(X) qui permet de créer 4 nouvelles colonnes dates:
-date1 : Matin/journée/soir/nuit (6h-10h; 10h-18h; 18h-22h; 22h-6h)
-date2 : jours de la semaine 
-date3 : week-end/semaine 
-date4 : mois 
Cela nous permettra de pouvoir les comparer afin d'en déduire quel critère est le plus pertinent.

On l'a ajouté au fichier csv.


2)
On a supprimé les features qui nous paraissaient moins pertinentes. 


3)(Martin) 
Création du fichier affichage.ipynb afin de mieux visualiser les données. → Suite : L'appeler avec le nouveau fichier .csv qui sera nettoyé et modifié (grâce à 1), 2), et l'essaye de onehot qu'on va faire)

4) On a essayé de faire un tableau onehot mais on a pas assez de mémoire ram pour que ça fonctionne. Alors on a fait un encodage OrdinalEncoder.
--> Détail : Faire un onehot des 3 colonnes primary description... nosu rajoute 700 features, et 700 millions de données c'est un peu beaucoup

5) Création de la classe Kmeans.py 

6) On a essayé d'utliser la classe Kmeans à notre dataset : ça donne une belle image de Chicago, cependant on a un cluster qui prédomine anormalement sur les autres, à approfondir.

7) Essaie avec la classe Kmeans SKlearn: enorme gain de performance, 
plus de problème de clusters qui disparaissent.

TODO à faire à la prochaine séance : 

-Créer une classe main.py pour avoir une base qui marche bien
-Essayer d'utiliser le PCA et voir ce que ça donne


=== 1ER AVRIL 2021 ===

0)
Au finale on a utilié la class kmeans de scikit_learn et ça marche, pas de bug

1)
Création de la classe preprocessing (nom à changer) à partir de data.py!
En gros on a regroupé en fonctions le bouts de codes qui trainaient. Et ça compile! 
Du coup maintenant on a des fonctions à appeler relativement facilement.

2)
Création de la classe train.py qui va nous permettre d'entraîner nos données

3)
Création de la classe main.py qui va nous permettre de tester tout notre programme, super!

=== 2 AVRIL 2021 ===

1) Ajouts de l'affichage de l'encodage dans le main

2) Ajout d'un fichier commandes qui contient l'ensemble des commandes shell qui 
permettent de manipuler le data set.

3) Dans le preprocessing.py, ajout du split data → X/Y

4) Gestion du header donc on pourra facilement retrouver quelle colonne correspond 
à quelle feature.

5) Ajout du README

6) Affichage beaucoup plus évolué où les clusters les plus important ont une couleur plus
vive.

=== 4 AVRIL 2021 ===

1) Gain de temps en sauvegardant les données préprocessés

2) Training en GaussianNB et DecisionTreeClassifier

3) Equilibrage du dataset (voir le fichier commandes)

TODO à faire à la prochaine séance : 
-Essayer d'utiliser le PCA et voir ce que ça donne
