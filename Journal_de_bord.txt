=== 28 MARS 2021 ===

1)
Création de la fonction split_date(X) qui permet de créer 4 nouvelles colonnes dates:
-date1 : Matin/journée/soir/nuit (6h-10h; 10h-18h; 18h-22h; 22h-6h)
-date2 : jours de la semaine 
-date3 : week-end/semaine 
-date4 : mois 
Cela nous permettra de pouvoir les comparer afin d'en déduire quel critère est le plus pertinent.

On l'a ajouté au fichier csv.


2)
On a supprimé les features qui nous paraissaient moins pertinentes. 


3)(Martin) 
Création du fichier affichage.ipynb afin de mieux visualiser les données. → Suite : L'appeler avec le nouveau fichier .csv qui sera nettoyé et modifié (grâce à 1), 2), et l'essaye de onehot qu'on va faire)

4) On a essayé de faire un tableau onehot mais on a pas assez de mémoire ram pour que ça fonctionne. Alors on a fait un encodage OrdinalEncoder.
--> Détail : Faire un onehot des 3 colonnes primary description... nosu rajoute 700 features, et 700 millions de données c'est un peu beaucoup

5) Création de la classe Kmeans.py 

6) On a essayé d'utliser la classe Kmeans à notre dataset : ça donne une belle image de Chicago, cependant on a un cluster qui prédomine anormalement sur les autres, à approfondir.

7) Essaie avec la classe Kmeans SKlearn: enorme gain de performance, 
plus de problème de clusters qui disparaissent.


=== 1ER AVRIL 2021 ===

- Au finale on a utilié la class kmeans de scikit_learn et ça marche, pas de bug
- Création de la classe preprocessing (nom à changer) à partir de data.py!
- En gros on a regroupé en fonctions le bouts de codes qui trainaient. Et ça compile! 
- Du coup maintenant on a des fonctions à appeler relativement facilement.
- Création de la classe train.py qui va nous permettre d'entraîner nos données
- Création de la classe main.py qui va nous permettre de tester tout notre programme, super!

=== 2 AVRIL 2021 ===

- Ajouts de l'affichage de l'encodage dans le main
- Ajout d'un fichier commandes qui contient l'ensemble des commandes shell qui 
permettent de manipuler le data set.
- Dans le preprocessing.py, ajout du split data → X/Y
- Gestion du header donc on pourra facilement retrouver quelle colonne correspond quelle feature.
- Ajout du README
- Affichage beaucoup plus évolué où les clusters les plus important ont une couleur plus
vive.

=== 4 AVRIL 2021 ===

- Gain de temps en sauvegardant les données préprocessés
- Training en GaussianNB et DecisionTreeClassifier : score 0.89
- Equilibrage du dataset (voir le fichier commandes)
- Optimisation des paramètres du DecisionTreeClassifier 

=== 5 AVRIL 2021 ===

- Score : entre 0.90 et 0.92 suivant les données
- Recherche du meilleur nombre de cluster
- Affichage de l'importance des features : 
	- On voit que beaucoup de nos features n'ont pas beaucoup d'influence

TODO à faire à la prochaine séance : 
- Sauvegarder l'encodage dans un fichier pour qu'il soit disponible quand on ne refait pas le 
préprocessing
- Essayer d'utiliser le PCA et voir ce que ça donne
